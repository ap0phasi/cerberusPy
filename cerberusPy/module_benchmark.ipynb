{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "\n",
    "from preprocess import create_min_max_df, scale_data, downsample_timeseries_data, slice_timeseries_data, masked_expand\n",
    "from postprocess import generate_predictions\n",
    "\n",
    "import importlib\n",
    "import time\n",
    "\n",
    "# modules = ['cerberus_builder_noknown']\n",
    "modules = ['cerberus_builder', \n",
    "           'cerberus_builder_attention',\n",
    "           'cerberus_builder_attention_noneck',\n",
    "           'cerberus_builder_noneck',\n",
    "           'cerberus_builder_attention_hybrid',\n",
    "           'cerberus_builder_noknown'\n",
    "           ]\n",
    "\n",
    "# Setup\n",
    "df = pd.read_csv(r\"../data/jena_climate_2009_2016.csv\",\n",
    "                parse_dates=['Date Time'], \n",
    "                index_col=['Date Time'])\n",
    "df.index = pd.to_datetime(df.index, format='%d.%m.%Y %H:%M:%S')\n",
    "df = df.iloc[:5000,:]\n",
    "context_windows = ['1H', '2H', '6H']\n",
    "context_sizes = [24, 12, 6]\n",
    "call_window = '10T'\n",
    "call_size = 24\n",
    "response_window = '10T'\n",
    "response_size = 8\n",
    "call_feature_index = range(0,14)\n",
    "context_feature_index = [range(0,14),\n",
    "                        range(0,14),\n",
    "                        range(0,14)]\n",
    "response_feature_index = [0, 1, 4]\n",
    "thresholds = {\n",
    "    'call': 0.7,\n",
    "    'response': 0.7,\n",
    "    'context_0': 0.7,\n",
    "    'context_1': 0.7,\n",
    "    'context_2': 0.7\n",
    "}\n",
    "sizes = {\n",
    "    'call': 24,\n",
    "    'response': 8,\n",
    "    'context_0': 24,\n",
    "    'context_1': 12,\n",
    "    'context_2': 6\n",
    "}\n",
    "\n",
    "#Scale Data\n",
    "min_max_df = create_min_max_df(df)\n",
    "\n",
    "scaled_df = scale_data(df, min_max_df, feature_range=(0, 1))\n",
    "\n",
    "downsampled_data = downsample_timeseries_data(scaled_df, \n",
    "                                        context_windows, \n",
    "                                        call_window, \n",
    "                                        response_window,\n",
    "                                        call_feature_index,\n",
    "                                        context_feature_index,\n",
    "                                        response_feature_index)\n",
    "\n",
    "sliced_data, selected_timestamps = slice_timeseries_data(downsampled_data,\n",
    "                                    sizes,\n",
    "                                    thresholds)\n",
    "\n",
    "expanded_dict, response_data = masked_expand(sliced_data, sizes)\n",
    "\n",
    "# Placeholder for results\n",
    "results = []\n",
    "models = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cerberus_builder\n",
      "Epoch 1/30\n",
      "1084/1084 [==============================] - 61s 52ms/step - loss: 0.0044 - val_loss: 0.0015\n",
      "Epoch 2/30\n",
      "1084/1084 [==============================] - 50s 46ms/step - loss: 6.2629e-04 - val_loss: 0.0011\n",
      "Epoch 3/30\n",
      "1084/1084 [==============================] - 50s 46ms/step - loss: 4.3738e-04 - val_loss: 0.0011\n",
      "Epoch 4/30\n",
      "1084/1084 [==============================] - 50s 46ms/step - loss: 3.4411e-04 - val_loss: 9.6405e-04\n",
      "Epoch 5/30\n",
      "1084/1084 [==============================] - 56s 52ms/step - loss: 3.0100e-04 - val_loss: 0.0011\n",
      "Epoch 6/30\n",
      "1084/1084 [==============================] - 52s 48ms/step - loss: 2.6783e-04 - val_loss: 9.2172e-04\n",
      "Epoch 7/30\n",
      "1084/1084 [==============================] - 50s 46ms/step - loss: 2.5658e-04 - val_loss: 9.3792e-04\n",
      "Epoch 8/30\n",
      "1084/1084 [==============================] - 50s 46ms/step - loss: 2.3866e-04 - val_loss: 8.9259e-04\n",
      "Epoch 9/30\n",
      "1084/1084 [==============================] - 51s 47ms/step - loss: 2.2108e-04 - val_loss: 9.2239e-04\n",
      "Epoch 10/30\n",
      "1084/1084 [==============================] - 46s 42ms/step - loss: 2.1260e-04 - val_loss: 9.3742e-04\n",
      "Epoch 11/30\n",
      "1084/1084 [==============================] - 44s 41ms/step - loss: 1.9704e-04 - val_loss: 0.0011\n",
      "Epoch 12/30\n",
      "1084/1084 [==============================] - 43s 40ms/step - loss: 1.8984e-04 - val_loss: 9.4122e-04\n",
      "Epoch 13/30\n",
      "1084/1084 [==============================] - 44s 41ms/step - loss: 1.7449e-04 - val_loss: 0.0011\n",
      "Epoch 14/30\n",
      " 261/1084 [======>.......................] - ETA: 38:56:28 - loss: 1.7894e-04"
     ]
    }
   ],
   "source": [
    "# Loop through each module and perform tests\n",
    "for module_name in modules:\n",
    "    print(module_name)\n",
    "    # Dynamically import the required functions\n",
    "    module = importlib.import_module(module_name)\n",
    "    build_cerberus = getattr(module, 'build_cerberus')\n",
    "    train_cerberus = getattr(module, 'train_cerberus')\n",
    "    \n",
    "    tic = time.time()\n",
    "    # Test cerberus\n",
    "    model = build_cerberus(expanded_dict, response_data, 64)\n",
    "    model = train_cerberus(model,expanded_dict, response_data, 30)\n",
    "    \n",
    "    train_call = expanded_dict['call']\n",
    "    train_contexts = [expanded_dict[key] for key in expanded_dict if 'context' in key]\n",
    "    train_response = expanded_dict['response']\n",
    "    \n",
    "    predicted = model.predict([train_call] + train_contexts + [train_response])\n",
    "\n",
    "    training_rmse = np.sqrt(np.mean((predicted - response_data) ** 2))\n",
    "    \n",
    "    # Check individual generation\n",
    "    selected_data = {key: value[400:401,:] for key, value in sliced_data.items()}\n",
    "    responses_generated = generate_predictions(model,selected_data)\n",
    "    observed = selected_data['response'][0,:,:]\n",
    "    \n",
    "    generated_rmse = np.sqrt(np.mean((responses_generated - observed) ** 2))\n",
    "    \n",
    "    toc = time.time()\n",
    "     \n",
    "    total_time = toc-tic\n",
    "    \n",
    "    # Record results\n",
    "    results.append({\n",
    "        'module': module_name,\n",
    "        'train_time': total_time,\n",
    "        'training_rmse': training_rmse,\n",
    "        'generated_rmse':  generated_rmse\n",
    "    })\n",
    "    models.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the best model\n",
    "min_index = results_df['generated_rmse'].idxmin()\n",
    "model = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = {key: value[400:401,:] for key, value in sliced_data.items()}\n",
    "responses_generated = generate_predictions(model,selected_data)\n",
    "print(selected_data['response'])\n",
    "print(responses_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example matrices\n",
    "observed = selected_data['response'][0,:,:]\n",
    "modeled = responses_generated\n",
    "\n",
    "# Number of rows and columns\n",
    "num_rows, num_cols = observed.shape\n",
    "\n",
    "# Create a plot for each feature (column)\n",
    "for i in range(num_cols):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(observed[:, i], label='Observed - Feature {}'.format(i+1))\n",
    "    plt.plot(modeled[:, i], label='Modeled - Feature {}'.format(i+1))\n",
    "    plt.title(f'Feature {i+1} Comparison')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
