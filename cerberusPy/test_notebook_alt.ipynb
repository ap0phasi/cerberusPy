{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "\n",
    "from cerberus_builder import build_cerberus, train_cerberus\n",
    "from preprocess import create_min_max_df, scale_data, downsample_timeseries_data, slice_timeseries_data, masked_expand\n",
    "from postprocess import generate_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "df = pd.read_csv(r\"../data/jena_climate_2009_2016.csv\",\n",
    "                parse_dates=['Date Time'], \n",
    "                index_col=['Date Time'])\n",
    "df.index = pd.to_datetime(df.index, format='%d.%m.%Y %H:%M:%S')\n",
    "df = df.iloc[:5000,:]\n",
    "context_windows = ['1H', '2H', '6H']\n",
    "context_sizes = [24, 12, 6]\n",
    "call_window = '10T'\n",
    "call_size = 24\n",
    "response_window = '10T'\n",
    "response_size = 8\n",
    "call_feature_index = range(0,14)\n",
    "context_feature_index = [range(0,14),\n",
    "                        range(0,14),\n",
    "                        range(0,14)]\n",
    "response_feature_index = [0, 1, 4]\n",
    "thresholds = {\n",
    "    'call': 0.7,\n",
    "    'response': 0.7,\n",
    "    'context_0': 0.7,\n",
    "    'context_1': 0.7,\n",
    "    'context_2': 0.7\n",
    "}\n",
    "sizes = {\n",
    "    'call': 24,\n",
    "    'response': 8,\n",
    "    'context_0': 24,\n",
    "    'context_1': 12,\n",
    "    'context_2': 6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale Data\n",
    "min_max_df = create_min_max_df(df)\n",
    "print(min_max_df)\n",
    "scaled_df = scale_data(df, min_max_df, feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_data = downsample_timeseries_data(scaled_df, \n",
    "                                        context_windows, \n",
    "                                        call_window, \n",
    "                                        response_window,\n",
    "                                        call_feature_index,\n",
    "                                        context_feature_index,\n",
    "                                        response_feature_index)\n",
    "downsampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_data, selected_timestamps = slice_timeseries_data(downsampled_data,\n",
    "                                    sizes,\n",
    "                                    thresholds)\n",
    "\n",
    "sliced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in sliced_data:\n",
    "    print(sliced_data[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_dict, response_data = masked_expand(sliced_data, sizes)\n",
    "\n",
    "print(response_data[0,:])\n",
    "for ir in range(30):\n",
    "    print(expanded_dict['response'][ir,:,:])\n",
    "    \n",
    "for key in expanded_dict:\n",
    "    print(expanded_dict[key].shape)\n",
    "    \n",
    "print(response_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_cerberus(expanded_dict, response_data, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_cerberus(model,expanded_dict, response_data, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = {key: value[400:401,:] for key, value in sliced_data.items()}\n",
    "responses_generated = generate_predictions(model,selected_data)\n",
    "print(selected_data['response'])\n",
    "print(responses_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example matrices\n",
    "observed = selected_data['response'][0,:,:]\n",
    "modeled = responses_generated\n",
    "\n",
    "# Number of rows and columns\n",
    "num_rows, num_cols = observed.shape\n",
    "\n",
    "# Create a plot for each feature (column)\n",
    "for i in range(num_cols):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(observed[:, i], label='Observed - Feature {}'.format(i+1))\n",
    "    plt.plot(modeled[:, i], label='Modeled - Feature {}'.format(i+1))\n",
    "    plt.title(f'Feature {i+1} Comparison')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
